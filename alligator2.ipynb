{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alligator2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "P9eCcmbJUiIB",
        "KsbpSqDIaq7A",
        "KzhXP3VEWi4R",
        "SE9SMR1WuD_s",
        "c_t7cMdnoH-h",
        "hDG0vYStqoCp",
        "LbIu0fWANAw5",
        "9HYX6lm-LeqQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9eCcmbJUiIB"
      },
      "source": [
        "# Make a copy of this notebook! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsbpSqDIaq7A"
      },
      "source": [
        "# Intro to Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuo6MXz7KXpM"
      },
      "source": [
        "**60 second crash course in Colab notebooks**\n",
        "\n",
        "A notebook is a list of cells. Cells contain either **explanatory text** or **executable code** and its output. This is a **text cell**. You can double-click to edit this cell.\n",
        "\n",
        "Once the toolbar button indicates CONNECTED, click in the cell to select it and execute the contents in the following ways:\n",
        "\n",
        "* Click the **Play icon** in the left gutter of the cell; or\n",
        "* Type **Cmd/Ctrl + Enter** to run the cell in place.\n",
        "\n",
        "Good to know\n",
        "* **Hashtags (#)** are Python comments (they're ignored during code execution)\n",
        "* Use **Cmd/Ctrl + / ** to comment out a line of code (helpful during debugging)\n",
        "* When you execute a code block, anything within that code block can be referenced elsewhere in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psHZilLIH3ww"
      },
      "source": [
        "# Printing to screen\n",
        "print(\"I'm a code block\")\n",
        "\n",
        "# Defining variables\n",
        "a = 2\n",
        "b = 5\n",
        "c = a + b\n",
        "print(f\"a equals {a}\")\n",
        "print(f\"b equals {b}\")\n",
        "print(f\"a plus b equals {c}\")\n",
        "\n",
        "# Proper indentation is essential in Python\n",
        "for x in range(1,6):\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WwBV_BrUeq-"
      },
      "source": [
        "# Alligator 2.0 Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqfyCrSBy8Um"
      },
      "source": [
        "This notebook contains the steps necessary to set up the Google My Business (GMB) [Insights](https://developers.google.com/my-business/reference/rest/v4/Metric) extraction and aggregation tool known as [Alligator 2.0](https://github.com/google/alligator2), as well as the visualization of the extracted insights in a Google Data Studio dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzhXP3VEWi4R"
      },
      "source": [
        "## Solution Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ1UkI2zoBI-"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc1PRFQEUhjz"
      },
      "source": [
        "\n",
        "Alligator 2.0 (Alligator for short) is a Python-based solution that aggregates *Insights* data from the GMB API and stores it into Google Cloud Platform, precisely in BigQuery. *Insights* data provides details around how users interact with GMB listings via Google Maps, such as the number of queries for a location, locations of where people searched for directions, number of website clicks, calls, and reviews.\n",
        "\n",
        "The solution provides a cross-account look at the GMB data, instead of a per-location view. In addition, the use of BigQuery to aggregate and store this data allows trends longer than the range accessible through the GMB API to be captured.\n",
        "\n",
        "Along with gathering stats, the Natural Language API from Cloud has been used to provide sentiment analysis, as well as entity detection for supported languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZGRPQIMYAuB"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asseR1lCYG1x"
      },
      "source": [
        "Alligator is a process built in Python that pulls data from the GMB API and gathers it into a BigQuery instance.\n",
        "\n",
        "The process uses the publicly available GMB API, along with the Big Query API to access, download and aggregate the data. Access is gained using standard OAuth tokens, which are stored in the runtime environment executing the Python process.\n",
        "\n",
        "Once aggregated, tables are created in BigQuery, and the reviews are processed using the NLP API on Cloud to get their sentiment information.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE9SMR1WuD_s"
      },
      "source": [
        "## GMB Account Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrsHLznWuHvk"
      },
      "source": [
        "\n",
        "*   All locations must roll up to a `Location Group` (formerly known as a `Business Account`). If this is not the case, please create a single Location Group and add all locations to it. Click [here](https://support.google.com/business/answer/6085339?ref_topic=6085325) for more information.<br/>Multiple location groups are supported and can be queried accordingly (refer to the [BigQuery Views section](#bigquery-views) below).\n",
        "*   The user accessing the GMB UI must have *Admin* privileges set for the Location Group(s).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_t7cMdnoH-h"
      },
      "source": [
        "## GCP Project Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N7DspDXoO5Q"
      },
      "source": [
        "To get started, you first need to create or select an existing Google Cloud Platform Project that is allowed to access the GMB API. For more information on getting access, refer to [this guide](https://developers.google.com/my-business/content/prereqs#request-access).\n",
        "\n",
        "Once your project is created and approved, the GMB API will automatically be enabled for use within the project (if not, enable it using this [link](https://console.developers.google.com/start/api?id=mybusiness.googleapis.com&credential=client_key)). Additionally, please enable the following APIs:\n",
        "\n",
        "*   [Cloud Natural Language API](https://console.developers.google.com/start/api?id=language.googleapis.com&credential=client_key)\n",
        "*   [BigQuery API](https://console.developers.google.com/start/api?id=bigquery&credential=client_key)\n",
        "\n",
        "Make sure that the user with access to the GMB UI/API also has permission to access the other APIs as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITkaM4zOqavg"
      },
      "source": [
        "### Authentication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f4TyuuzqnO7"
      },
      "source": [
        "The APIs are authenticated via OAuth, which means that you authenticate as a user as opposed to as an application. Your user permissions control what you have access to. If you don't have access in the UI you cannot access via the API.\n",
        "\n",
        "The client secrets give your application permission to access the API using your user credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWK66NQnbfGD"
      },
      "source": [
        "1. Go to the [API & Services > Credentials](https://console.cloud.google.com/apis/credentials) page on Google Cloud and select the project for which you enabled the APIs earlier.\n",
        "1. Create an OAuth 2.0 Client ID of the type *Desktop App*.\n",
        "1. Download the client secrets json file and save it as `client_secrets.json`.\n",
        "\n",
        "  > ![Download JSON](https://cloud.google.com/bigquery/images/download-json.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EG-cH7w95p3w"
      },
      "source": [
        "#@markdown Authenticate your user for this colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDG0vYStqoCp"
      },
      "source": [
        "## Installation Guide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "q_XbrZWnZgcE"
      },
      "source": [
        "#@markdown Set a global flag representing your GCP Project ID\n",
        "PROJECT_ID = '<your-project-id-here>'  # @param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zeCC3D6NWqrV"
      },
      "source": [
        "#@markdown Clone the alligator2 GitHub repository and cd into it\n",
        "\n",
        "!echo \"Restoring working directory to root...\"\n",
        "%cd /content\n",
        "!rm -rf alligator2 && git clone https://github.com/google/alligator2.git\n",
        "!echo \"Changing working directory to alligator2...\"\n",
        "%cd alligator2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "t_NXj2sV0wnX"
      },
      "source": [
        "#@markdown Copy the client_secrets.json file into the alligator2 directory\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('Uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xjcyEMwa3NQJ"
      },
      "source": [
        "#@markdown Install the application's required packages\n",
        "\n",
        "!pip3 install --upgrade --requirement requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "o9GWQaAI3xHZ"
      },
      "source": [
        "#@markdown Download the GMB API discovery document\n",
        "#@markdown <br/>*Refer to this*\n",
        "#@markdown [*link*](https://developers.google.com/my-business/samples/#discovery_document)\n",
        "#@markdown *for the latest available discovery document as the one used here may have been outdated*\n",
        "\n",
        "!wget -O gmb_discovery.json https://developers.google.com/my-business/samples/mybusiness_google_rest_v4p7.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B4jJ6_h5prK"
      },
      "source": [
        "Now you are all set; execute the cell below to run the application and start extracting and aggregating GMB data!\n",
        "\n",
        "Refer to the [CLI Usage](https://github.com/google/alligator2#usage-of-the-cli) section of the GitHub documentation for more information on the different flags you can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q63kLlKl6B-9"
      },
      "source": [
        "!python3 main.py --project_id=$PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A8v3oeHKPJe"
      },
      "source": [
        "Depending on the amount of GMB source data you have across your locations and location groups, the frequency of analysis may differ.\n",
        "<br/>Usually, a weekly workflow suffices for capturing enough insights. Refer to the [Maintenance Guide](#scrollTo=LbIu0fWANAw5) section below for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiOYvsUT8qUb"
      },
      "source": [
        "You can also fine-tune the constants referenced in [api.py](https://github.com/google/alligator2/blob/master/api.py) to fit your data volume and indiviual use cases. The predefined values are optimized for the extraction of significantly large volumes of data without running into [operational](https://cloud.google.com/bigquery/quotas#streaming_inserts) / transactional limits.\n",
        "\n",
        "```python\n",
        "DATASET_ID = \"alligator\"\n",
        "\n",
        "# max lookback window for insights metrics in days\n",
        "INSIGHTS_DAYS_BACK = 540 \n",
        "\n",
        "# calls metrics are aggregated in GMB, this value supports a weekly workflow\n",
        "CALLS_DAYS_BACK = 7 \n",
        "\n",
        "# directions metrics are limited to predefined values in GMB, this value supports a weekly workflow\n",
        "DIRECTIONS_NUM_DAYS = \"SEVEN\" \n",
        "\n",
        "# max number of rows of data to retrieve from BQ. Used when processing sentiments for existing reviews\n",
        "BQ_JOBS_QUERY_MAXRESULTS_PER_PAGE = 1000 \n",
        "\n",
        "# max batch size for BQ streaming inserts. Do not change this value as you might run into API limits\n",
        "BQ_TABLEDATA_INSERTALL_BATCHSIZE = 50\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yUfY-bRb7qr"
      },
      "source": [
        "Once the script is run, your BigQuery dataset will be populated with several tables depending on the execution flags used.<br/>\n",
        "Execute the next cell to view your dataset's contents (make sure you change the dataset name if you are not using the default 'alligator')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef3nOXQqxfvQ",
        "cellView": "code"
      },
      "source": [
        "%%bigquery --project $PROJECT_ID\n",
        "\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  alligator.INFORMATION_SCHEMA.TABLES;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRFQ1Nj40EYf"
      },
      "source": [
        "Here is a description of each table and the extraction methods used: \n",
        "\n",
        "*   **accounts**: Provides information on the accounts (e.g., location groups) associated to the user. It is omitted if running for a specific account using the `--account_id` switch.\n",
        "*   **locations**: Provides information about locations associated to the user through the GMB accounts. It is omitted if running for a specific location using the `--location_id` switch.\n",
        "*   **insights**: Executes the [reportInsights](https://developers.google.com/my-business/reference/rest/v4/accounts.locations/reportInsights) method and gets all the information under Location Metrics, aggregated by day, for the last 540 days (with 5 days delay) for all associated locations. This range can be modified in the code.\n",
        "*   **directions**: Executes the [reportInsights](https://developers.google.com/my-business/reference/rest/v4/accounts.locations/reportInsights) method and gets all the information under Driving Direction Metrics, for the last 7 days for all associated locations. This range can be modified to one of the allowed ones (7, 30 or 90 days).\n",
        "*   **hourly_calls**: Executes the [reportInsights](https://developers.google.com/my-business/reference/rest/v4/accounts.locations/reportInsights) method and gets all the phone actions aggregated by hour of the day, for the last 7 days (with 5 days delay) for all associated locations. This range can be modified in the code, but consistency of the data will depend on the extraction schedule and the range complementariness.\n",
        "*   **reviews**: Provides all the reviews available in the API for all associated locations.\n",
        "*   **sentiments**: Provides the sentiment extracted for all the reviews present in the reviews table at execution time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbIu0fWANAw5"
      },
      "source": [
        "## Maintenance Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iekTzjdfNAw6"
      },
      "source": [
        "Data extracted by Alligator needs to be maintained in order to be consistent, up to date and GDPR compliant.\n",
        "\n",
        "On the compliance side, any user can delete a review in GMB, and the data owner is responsible for deleting all copies of it in their systems. Unfortunately the GMB API does not provide a means to get information on deleted reviews. The workaround for this is to extract all reviews periodically, and delete old copies from the data lake.\n",
        "\n",
        "To ensure consistency, and as the extraction process could duplicate information, all the tables are partitioned by day of extraction to facilitate deletion of old data.\n",
        "\n",
        "On the same note, the `directions` and `hourly_calls` are different from other tables in that their information is aggregated (`hourly_calls`), or limited to predefined ranges (`directions`) in the API. For that, it is recommended to avoid deleting these two tables periodically, in case you want to extend the lookback window farther than as provided by the API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si9C8SieNMbc"
      },
      "source": [
        "### Weekly Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl5Y9x1CNQLg"
      },
      "source": [
        "Alligator is prepared to use this workflow, and we propose the following approach to handle extractions and deletions.\n",
        "\n",
        "*   Day 01: the extraction is run completely.\n",
        "*   Day 02 to 07: nothing.\n",
        "*   Day 08: prior to running the extraction completely, manually delete all data with `_PARTITIONTIME < TODAY` from all tables, except for *directions* and *hourly_calls*.\n",
        "*   Day 08 to 14: nothing.\n",
        "*   Day 15: prior to running the extraction completely, manually delete all data with `_PARTITIONTIME < TODAY` from all tables, except for *directions* and *hourly_calls*.\n",
        "<br/>...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RijqBGKfNeCM"
      },
      "source": [
        "### Daily Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSoBmf17NeCN"
      },
      "source": [
        "In case there is a need to get information as soon as possible, there is an alternative approach, but it might require a bit more maintenance.\n",
        "\n",
        "*   Day 01: the extraction is run completely.\n",
        "*   Day 02: the extraction is run with the `--no-directions` and `--no-hourly-calls` flag. Before doing that, all data with `_PARTITIONTIME < TODAY` should be manually deleted from all tables, except for *directions* and *hourly_calls*.\n",
        "*   Day 03: (same as Day 02)\n",
        "*   Day 04: (same as Day 02)\n",
        "*   Day 05: (same as Day 02)\n",
        "*   Day 06: (same as Day 02)\n",
        "*   Day 07: (same as Day 02)\n",
        "*   Day 08: prior to running the extraction completely, manually delete all data with `_PARTITIONTIME < TODAY` from all tables, except for *directions* and *hourly_calls*.\n",
        "*   Day 09: (same as Day 02)\n",
        "*   Day 10: (same as Day 02)\n",
        "*   Day 11: (same as Day 02)\n",
        "*   Day 12: (same as Day 02)\n",
        "*   Day 13: (same as Day 02)\n",
        "*   Day 14: (same as Day 02)\n",
        "*   Day 15: prior to running the extraction completely, manually delete all data with `_PARTITIONTIME < TODAY` from all tables, except for *directions* and *hourly_calls*.\n",
        "<br/>...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HYX6lm-LeqQ"
      },
      "source": [
        "## Reporting Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBUw-3PZKjSX"
      },
      "source": [
        "Now that the data is available in BigQuery we can build the Data Studio Dashboard. First, let's try to visualize some of the data you have extracted so far. As an example, the code below will aggregate the star rating of all your reviews (across all your locations):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "084JQjo2Lbxm"
      },
      "source": [
        "%%bigquery reviews_agg_rating --project $PROJECT_ID\n",
        "\n",
        "SELECT\n",
        "  r.starRating AS rating,\n",
        "  count(1) AS count_rating\n",
        "FROM \n",
        "  alligator.reviews AS r\n",
        "GROUP BY r.starRating\n",
        "ORDER BY (\n",
        "  CASE r.starRating\n",
        "    WHEN \"ONE\" then 1\n",
        "    WHEN \"TWO\" then 2\n",
        "    WHEN \"THREE\" then 3\n",
        "    WHEN \"FOUR\" then 4\n",
        "    WHEN \"FIVE\" then 5\n",
        "  END\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ytll9u3LXkE"
      },
      "source": [
        "Now let's plot the data using [matplotlib](https://matplotlib.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rIReYjsLbAK"
      },
      "source": [
        "%matplotlib inline\n",
        "reviews_agg_rating.plot(kind=\"bar\", x=\"rating\", y=\"count_rating\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-S8BuOARDgc"
      },
      "source": [
        "Let's keep going and identify the top 10 locations based on review rating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvhT1DnqREmn"
      },
      "source": [
        "%%bigquery --project $PROJECT_ID\n",
        "\n",
        "WITH location_reviews AS (\n",
        "  SELECT \n",
        "    l.locationName,\n",
        "    (CASE\n",
        "      WHEN r.starRating = \"ONE\" THEN 1\n",
        "      WHEN r.starRating = \"TWO\" THEN 2\n",
        "      WHEN r.starRating = \"THREE\" THEN 3\n",
        "      WHEN r.starRating = \"FOUR\" THEN 4\n",
        "      WHEN r.starRating = \"FIVE\" THEN 5\n",
        "      ELSE NULL\n",
        "    END) AS numRating\n",
        "  FROM \n",
        "    alligator.reviews AS r\n",
        "  JOIN \n",
        "    alligator.locations AS l\n",
        "      ON l.name = REGEXP_EXTRACT(r.name, '(.*)/reviews/')\n",
        ")\n",
        "SELECT\n",
        "  locationName,\n",
        "  AVG(numRating) AS avgRating\n",
        "FROM \n",
        "  location_reviews\n",
        "WHERE numRating IS NOT NULL\n",
        "GROUP BY locationName\n",
        "ORDER BY avgRating DESC\n",
        "LIMIT 10;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBJgGpS_LgUK"
      },
      "source": [
        "Now that you have an idea of the different visualizations possible with this data, let's build the Data Studio Dashboard. You can use [this](https://datastudio.google.com/c/reporting/d86ca1bb-4255-4089-9adf-b99148bc5a94) dashboard template and copy it as-is, but first you will need to prepare the data sources beforehand. \n",
        "\n",
        "For this, you have two options:\n",
        "\n",
        "*   Create views within your GCP project's BigQuery dataset to supply the data to the dashboard; or\n",
        "*   Use Data Studio's *Custom Query* interface to directly input the views' SQL queries.\n",
        "\n",
        "It is recommended that you follow the first approach (views in BigQuery) for maintainability and performance reasons.\n",
        "\n",
        "*   To create a view in BigQuery, you can follow the steps described [here](https://cloud.google.com/bigquery/docs/views). You will need to create six views, and you can find sample SQL files in the [sql folder](https://github.com/google/alligator2/tree/master/sql) of the project (make sure to modify the Project ID and BigQuery dataset if you are not using the default).\n",
        ">Once the views are available, you need to link them to Data Studio by creating Data Sources as described [here](https://support.google.com/datastudio/answer/6370296?hl=en), and selecting the *My Projects or Shared Projects* options.\n",
        "\n",
        "*   If you prefer to go the *Custom Query* route, you can use the same [instructions](https://support.google.com/datastudio/answer/6370296?hl=en) to create the Data Sources but selecting the *Custom Query* option. You can also use the [sql samples](https://github.com/google/alligator2/tree/master/sql) as the custom queries on each Data Source.\n",
        "\n",
        "After the Data Sources are created, you can create a copy of the template and replace the sample data sources with the ones associated with your project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3DnBXEuN_hK"
      },
      "source": [
        "### Geographical Visualization for Driving Directions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it4mooD1M8I8"
      },
      "source": [
        "> *At the time of writing, Data Studio's built in _Geo_ and _Google Maps_ chart types did not support custom map overlays.*\n",
        "\n",
        "For example, say we want to plot both an existing location as a **pointer** on the map, along with a **polygon** representing all source postal codes from which driving directions originated.\n",
        "\n",
        "Since this is not currently possible with Data Studio, [BigQuery Geo Viz](https://bigquerygeoviz.appspot.com/) and/or [geojson.io](https://geojson.io) (among others) can be used instead.\n",
        "\n",
        "Follow the instructions below to plot this information for a given city and postal code pair using geojson.io. You could also materialize the SQL below as a view in BigQuery and use BigQuery Geo Viz for a more aggregated view (e.g. city-wide or even regional) of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pw8oBa061Bx-"
      },
      "source": [
        "#@markdown Enter the desired plotting params\n",
        "#@markdown <br/>*param_zipcode* and *param_address* are optional, \n",
        "#@markdown though it is highly recommended that you enter a postal code to view the effect of having multiple locations within the same area:\n",
        "param_city = '<city>'  # @param\n",
        "param_zipcode = '<zipcode>'  # @param\n",
        "param_address = ''  # @param\n",
        "\n",
        "params = {\n",
        "    'param_city': param_city,\n",
        "    'param_zipcode': param_zipcode,\n",
        "    'param_address': param_address\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "acchmFg312t4"
      },
      "source": [
        "#@markdown Fetch data from BigQuery and store it in a Pandas DataFrame named 'geo_data'.\n",
        "%%bigquery geo_data --project $PROJECT_ID --params $params\n",
        "\n",
        "WITH temp_data AS (\n",
        "  SELECT\n",
        "    regionCode AS countryCode,\n",
        "    locality AS city,\n",
        "    postalCode AS locationZipCode,\n",
        "    locationName AS locationName,\n",
        "    addressLines AS locationAddress,\n",
        "    label AS sourceZipCode,\n",
        "    latitude,\n",
        "    longitude\n",
        "  FROM \n",
        "    alligator.formatted_directions\n",
        "  WHERE SAFE_CAST(label AS NUMERIC) IS NOT NULL\n",
        "  ORDER BY city, locationName, locationAddress, locationZipCode, sourceZipCode\n",
        "), temp_aggregated_data AS (\n",
        "  SELECT distinct\n",
        "    regionCode AS countryCode,\n",
        "    locality AS city,\n",
        "    postalCode AS destinationZipCode,\n",
        "    label AS sourceZipCode,\n",
        "    latitude,\n",
        "    longitude\n",
        "  FROM \n",
        "    alligator.formatted_directions\n",
        "  WHERE SAFE_CAST(label AS NUMERIC) IS NOT NULL\n",
        "  ORDER BY city, destinationZipCode, sourceZipCode\n",
        "), temp_geo_data AS (\n",
        "  SELECT\n",
        "    d.countryCode,\n",
        "    d.city,\n",
        "    d.locationZipCode,\n",
        "    d.locationName,\n",
        "    d.locationAddress,\n",
        "    ARRAY_AGG(d.sourceZipCode ORDER BY d.sourceZipCode) AS sourceZipCodes,\n",
        "    ARRAY_AGG(ST_GeogPoint(d.longitude, d.latitude) ORDER BY d.sourceZipCode) AS sourceGeoPoints\n",
        "  FROM \n",
        "    temp_data AS d\n",
        "  GROUP BY countryCode, city, locationZipCode, locationName, locationAddress\n",
        "  ORDER BY countryCode, city, locationZipCode, locationName, locationAddress\n",
        "), temp_aggregated_geo_data AS (\n",
        "  SELECT\n",
        "    a.countryCode,\n",
        "    a.city,\n",
        "    a.destinationZipCode,\n",
        "    ARRAY_AGG(a.sourceZipCode ORDER BY a.sourceZipCode) AS sourceZipCodes,\n",
        "    ARRAY_AGG(ST_GeogPoint(a.longitude, a.latitude) ORDER BY a.sourceZipCode) AS sourceGeoPoints\n",
        "  FROM \n",
        "    temp_aggregated_data AS a\n",
        "  GROUP BY countryCode, city, destinationZipCode\n",
        "  ORDER BY countryCode, city, destinationZipCode\n",
        "), directions_geo AS (\n",
        "  SELECT \n",
        "    ag.countryCode,\n",
        "    ag.city,\n",
        "    ag.destinationZipCode,\n",
        "    ag.sourceZipCodes,\n",
        "    CASE \n",
        "      WHEN \n",
        "        ST_NUMPOINTS(ST_MAKELINE(ag.sourceGeoPoints)) >= 3 \n",
        "      THEN \n",
        "        ST_GEOGFROMGEOJSON(REPLACE(REPLACE(REPLACE(ST_ASGEOJSON(ST_MAKELINE(ag.sourceGeoPoints)), 'LineString', 'Polygon'), ': [ [', ':[[['), '] ] } ', ']]]}'), make_valid => true)\n",
        "      ELSE \n",
        "        ST_MAKELINE(ag.sourceGeoPoints)\n",
        "    END AS sourceZipCodesGeoPolygon,\n",
        "    g.locationName,\n",
        "    g.locationAddress,\n",
        "    g.sourceZipCodes AS locationSourceZipCodes,\n",
        "    CASE \n",
        "      WHEN \n",
        "        ST_NUMPOINTS(ST_MAKELINE(g.sourceGeoPoints)) >= 3 \n",
        "      THEN \n",
        "        ST_GEOGFROMGEOJSON(REPLACE(REPLACE(REPLACE(ST_ASGEOJSON(ST_MAKELINE(g.sourceGeoPoints)), 'LineString', 'Polygon'), ': [ [', ':[[['), '] ] } ', ']]]}'), make_valid => true)\n",
        "      ELSE \n",
        "        ST_MAKELINE(g.sourceGeoPoints)\n",
        "    END AS locationSourceZipCodesGeoPolygon\n",
        "  FROM \n",
        "    temp_aggregated_geo_data AS ag\n",
        "  JOIN temp_geo_data AS g\n",
        "    ON g.locationZipCode = ag.destinationZipCode\n",
        "  ORDER BY ag.countryCode, ag.city, ag.destinationZipCode, g.locationAddress\n",
        ")\n",
        "# The aformentioned temp tables can be stored as a BigQuery view named\n",
        "# directions_geo and queried below directly as alligator.directions_geo\n",
        "SELECT\n",
        "  city,\n",
        "  destinationZipCode,\n",
        "  locationName,\n",
        "  locationAddress,\n",
        "  ST_ASGEOJSON(locationSourceZipCodesGeoPolygon) AS geojson\n",
        "FROM\n",
        "  directions_geo\n",
        "WHERE\n",
        "  city = @param_city\n",
        "  AND destinationZipCode = (\n",
        "    CASE \n",
        "      WHEN \n",
        "        @param_zipcode = '' \n",
        "      THEN\n",
        "        destinationZipCode\n",
        "      ELSE\n",
        "        @param_zipcode\n",
        "    END\n",
        "  )\n",
        "  AND locationAddress = (\n",
        "    CASE \n",
        "      WHEN \n",
        "        @param_address = '' \n",
        "      THEN\n",
        "        locationAddress\n",
        "      ELSE\n",
        "        @param_address\n",
        "    END\n",
        "  )\n",
        ";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo0wVzmFl__l",
        "cellView": "both"
      },
      "source": [
        "#@markdown Output the DataFrame:\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", None)\n",
        "\n",
        "geo_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt72fduYcOdr"
      },
      "source": [
        "#@markdown We need to fetch a latitude, longitude pair for every location within the provided postal code.\n",
        "#@markdown <br/>Multiple locations will be visualized using different colors.\n",
        "#@markdown <br/><br/>Execute this cell to install all required packages.\n",
        "!pip3 install -U geocoder geojson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIEAxJIweb2z"
      },
      "source": [
        "#@markdown Execute this cell to create a [GeoJSON specification](https://geojson.org/) string.\n",
        "import geocoder\n",
        "import json\n",
        "import random\n",
        "\n",
        "from geojson import FeatureCollection, Feature, Point\n",
        "\n",
        "\n",
        "def geocode(city, zipcode, address):\n",
        "  g = geocoder.osm(f\"{address} {zipcode} {city}\", components=\"country:DE\")\n",
        "  return g.lng, g.lat\n",
        "\n",
        "\n",
        "def geodata_feature_point(row, color):\n",
        "  city = row.city\n",
        "  zipcode = row.destinationZipCode\n",
        "  name = row.locationName\n",
        "  address = row.locationAddress\n",
        "  \n",
        "  lng, lat = geocode(city, zipcode, address)\n",
        "  point = Point((lng, lat))\n",
        "\n",
        "  feature = Feature(geometry=point, properties={\n",
        "      'name': f'Location Pointer',\n",
        "      'popupContent': f'{name}<br>{address}<br>{zipcode} {city}',\n",
        "      'color': color\n",
        "  })\n",
        "\n",
        "  return feature\n",
        "\n",
        "\n",
        "def geodata_feature_polygon(row, color):\n",
        "  city = row.city\n",
        "  zipcode = row.destinationZipCode\n",
        "  name = row.locationName\n",
        "  address = row.locationAddress\n",
        "\n",
        "  j = json.loads(row.geojson)\n",
        "  feature = Feature(geometry=j, properties={\n",
        "      'name': f'Driving Directions Polygon',\n",
        "      'popupContent': f'Driving directions for:<br/>{name}<br>{address}<br>{zipcode} {city}',\n",
        "      'color': color\n",
        "  })\n",
        "  \n",
        "  return feature\n",
        "\n",
        "\n",
        "def gen_colors(number_of_colors):\n",
        "  colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
        "               for i in range(number_of_colors)]\n",
        "  \n",
        "  return colors\n",
        "\n",
        "\n",
        "def geodata_features():\n",
        "  features = []\n",
        "  points = []\n",
        "  polygons = []\n",
        "\n",
        "  colors = gen_colors(len(geo_data))\n",
        "\n",
        "  for index, row in geo_data.iterrows():\n",
        "    color = colors[index]\n",
        "    feature_point = geodata_feature_point(row, color)\n",
        "    points.append(feature_point)\n",
        "\n",
        "    feature_polygon = geodata_feature_polygon(row, color)\n",
        "    polygons.append(feature_polygon)\n",
        "\n",
        "  # Add polygons first to ensure that points are plotted above them\n",
        "  features.extend(polygons)\n",
        "  features.extend(points)\n",
        "\n",
        "  return features\n",
        "\n",
        "\n",
        "address = None\n",
        "if param_address != '':\n",
        "  address = param_address\n",
        "\n",
        "lng, lat = geocode(param_city, param_zipcode, address)\n",
        "feature_collection = FeatureCollection(geodata_features())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJACRNyd2fs"
      },
      "source": [
        "#@markdown Now execute this cell to visualize the data.\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Single curly braces are reserved for \"replacement fields\", escape curly braces in literal text by doubling them.\n",
        "display(HTML(f'''\n",
        "<link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.7.1/dist/leaflet.css\" integrity=\"sha512-xodZBNTC5n17Xt2atTPuE1HxjVMSvLVW9ocqUKLsCC5CXdbqCmblAshOMAS6/keqq/sMZMZ19scR4PsZChSR7A==\" crossorigin=\"\"/>\n",
        "<script src=\"https://unpkg.com/leaflet@1.7.1/dist/leaflet.js\" integrity=\"sha512-XQoYMqMTK8LvdxXYG3nZ448hOEQiglfqkJs1NOQV44cWnUrBc8PkAOcXy20w0vlaXaVUearIOBhiXZ5V3ynxwA==\" crossorigin=\"\"></script>\n",
        "\n",
        "<div id=\"mapid\" style=\"width: 600px; height: 400px;\"></div>\n",
        "<script>\n",
        "  function onEachFeature(feature, layer) {{\n",
        "    if (feature.properties && feature.properties.popupContent) {{\n",
        "      layer.bindPopup(feature.properties.popupContent);\n",
        "    }}\n",
        "  }}\n",
        "\n",
        "  function styles(feature) {{\n",
        "    if (feature.properties && feature.properties.color) {{\n",
        "      return {{\n",
        "        color: feature.properties.color\n",
        "      }};\n",
        "    }}\n",
        "  }}\n",
        "\n",
        "  function pointToLayer(feature, latlng) {{\n",
        "    var options = geojsonMarkerOptions;\n",
        "\n",
        "    if (feature.properties && feature.properties.color) {{\n",
        "       options.fillColor = feature.properties.color;\n",
        "    }}    \n",
        "    return L.circleMarker(latlng, options);\n",
        "  }}\n",
        "\n",
        "  var geojsonMarkerOptions = {{\n",
        "    radius: 8,\n",
        "    fillColor: \"#ff7800\",\n",
        "    color: \"#000\",\n",
        "    weight: 1,\n",
        "    opacity: 1,\n",
        "    fillOpacity: 0.8\n",
        "  }};\n",
        "\n",
        "\tvar map = L.map('mapid').setView([{lat}, {lng}], 12);\n",
        "\n",
        "\tL.tileLayer('https://api.mapbox.com/styles/v1/{{id}}/tiles/{{z}}/{{x}}/{{y}}?access_token=pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4NXVycTA2emYycXBndHRqcmZ3N3gifQ.rJcFIG214AriISLbB6B5aw', {{\n",
        "\t\tmaxZoom: 18,\n",
        "\t\tattribution: 'Map data &copy; <a href=\"https://www.openstreetmap.org/\">OpenStreetMap</a> contributors, ' +\n",
        "\t\t\t'<a href=\"https://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA</a>, ' +\n",
        "\t\t\t'Imagery © <a href=\"https://www.mapbox.com/\">Mapbox</a>',\n",
        "\t\tid: 'mapbox/streets-v11',\n",
        "\t\ttileSize: 512,\n",
        "\t\tzoomOffset: -1\n",
        "\t}}).addTo(map);\n",
        "\n",
        "  L.geoJSON({feature_collection}, {{\n",
        "      onEachFeature: onEachFeature,\n",
        "      style: styles,\n",
        "      pointToLayer: pointToLayer\n",
        "  }}).addTo(map);\n",
        "</script>\n",
        "'''))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
